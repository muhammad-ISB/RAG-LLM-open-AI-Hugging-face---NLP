# -*- coding: utf-8 -*-
"""demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10A9OeLQUQyHXf4KciA-VfWwa9Unv9nh9

### Install Packages
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install llama-index==0.10.18 llama-index-llms-groq==0.1.3 groq==0.4.2 llama-index-embeddings-huggingface==0.2.0

"""### Import Libraries"""

from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    ServiceContext,
    load_index_from_storage
)
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.node_parser import SentenceSplitter
from llama_index.llms.groq import Groq
# import os
# from dotenv import load_dotenv
# load_dotenv()
import warnings
warnings.filterwarnings('ignore')

from google.colab import userdata
GROQ_API_KEY = userdata.get('GROQ_API_KEY')
# GROQ_API_KEY = os.getenv("GROQ_API_KEY")

"""### Data Ingestion"""

# data ingestion
reader = SimpleDirectoryReader(input_files=["../Basics_of_finance.pdf"])
documents = reader.load_data()

"""https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/"""

len(documents)

documents[4].metadata

"""### Chunking"""

text_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=200)
nodes = text_splitter.get_nodes_from_documents(documents, show_progress=True)

"""https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules/"""

len(nodes)

nodes[0].metadata

"""https://chunkviz.up.railway.app/

### Embedding Model
"""

embed_model = HuggingFaceEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2")

"""https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2

https://huggingface.co/spaces/mteb/leaderboard

### Define LLM Model
"""

llm = Groq(model="llama3-70b-8192", api_key=GROQ_API_KEY)

"""https://console.groq.com/docs/models

https://console.groq.com/keys

### Configure Service Context
"""

service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=llm)

"""### Create Vector Store Index"""

vector_index = VectorStoreIndex.from_documents(documents, show_progress=True, service_context=service_context, node_parser=nodes)

"""https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/

#### Persist/Save Index
"""

vector_index.storage_context.persist(persist_dir="./storage_mini")

"""#### Define Storage Context"""

storage_context = StorageContext.from_defaults(persist_dir="./storage_mini")

"""https://docs.llamaindex.ai/en/stable/api_reference/storage/storage_context/

#### Load Index
"""

index = load_index_from_storage(storage_context, service_context=service_context)

"""### Define Query Engine"""

query_engine = index.as_query_engine(service_context=service_context)

"""https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/

#### Feed in user query

https://docs.llamaindex.ai/en/stable/examples/prompts/prompts_rag/#viewingcustomizing-prompts
"""

query = "Explain market bonds?"
resp = query_engine.query(query)

print(resp.response)

"""https://itsjb13.medium.com/building-a-rag-chatbot-using-llamaindex-groq-with-llama3-chainlit-b1709f770f55

https://docs.llamaindex.ai/en/stable/optimizing/production_rag/
"""